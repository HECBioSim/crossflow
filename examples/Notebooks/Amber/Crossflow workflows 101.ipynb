{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An introduction to Crossflow workflows\n",
    "\n",
    "In this notebook you will see how a simple MD simulation job can be converted from its normal command-line form into a Python function using tools in *Crossflow*.\n",
    "\n",
    "Then you will see how it's easy to chain jobs together to create a workflow.\n",
    "\n",
    "Requirements:\n",
    "\n",
    "1. *Amber* or *Ambertools* installed.\n",
    "2. Python packages *MDTraj* and *crossflow* installed.\n",
    "\n",
    "\n",
    "The notebook assumes you have a basic knowledge of *Amber*; some knowledge of *MDTraj* may also help, but is not obligatory.\n",
    "\n",
    "----\n",
    "\n",
    "### Part 1: running jobs the conventional way\n",
    "Have a look at the contents of this directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see:\n",
    "\n",
    "    Xbowflow workflows 101.ipynb : This notebook\n",
    "    dhfr.crd                     : Coordinates for DHFR in Amber .crd format\n",
    "    dhfr.prmtop                  : Amber topology file for DHFR\n",
    "    step1.mdin                   : An input file for sander/pmemd defining a restrained energy minimisation job\n",
    "    step2.mdin                   : An input file for sander/pmemd defining an unrestrained energy minimisation job\n",
    "    step1.mdin                   : An input file for sander/pmemd defining a short MD job\n",
    "    \n",
    "Let's begin by running the restrained energy minimisation job interactively in the conventional way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sander.MPI -O -i step1.mdin -c dhfr.crd -ref dhfr.crd -p dhfr.prmtop -o step1.mdout -r dhfr.step1.rst7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the job completed without errors, you should see the output files in the current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have a look at the log file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat step1.mdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Turning this into Python\n",
    "\n",
    "OK. Now you will see how you can turn the energy minimisation job from something you run on the command line (in this situation, within a Jupyter notebook, by using the \"!\" special command) into a pure Python function.\n",
    "\n",
    "The function will take a .crd file, a .prmtop file and a .mdin file as the input, and return the .mdout and .rst files when the job completes.\n",
    "\n",
    "So your aim is something like this:\n",
    "\n",
    "    restart, logfile = md(mdin, startcrds, prmtop)\n",
    "    \n",
    "---\n",
    "\n",
    "Begin by importing key elements of the *crossflow* module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crossflow import filehandling, kernels, clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you create the function, which in crossflow is called a **Kernel**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = kernels.SubprocessKernel('sander.MPI -O -i x.mdin -c x.rst7 -ref x.rst7 -p x.prmtop -o x.mdout -r out.rst7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The string used to create the kernel is a template for the command you want to run. The names of input and output files are arbitrary, but make sure they have the right extensions.\n",
    "\n",
    "---\n",
    "\n",
    "Now you have to tell the kernel what files are inputs, and what are outputs. To do this you pass *lists* of strings that correspond to the filenames in the template above. \n",
    "\n",
    "**NB:** the order of the strings in the inputs list defines the order that input variables will be passed to the kernel, and the order of the strings in the output list defines the order that the outputs from the function will appear in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give the kernel the signature: restart, logfile = md.run(mdin, startcrds, prmtop)\n",
    "md.set_inputs(['x.mdin', 'x.rst7', 'x.prmtop'])\n",
    "md.set_outputs(['out.rst7', 'x.mdout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's about it - your new function is ready for use.\n",
    "\n",
    "However, your data is not quite ready. Crossflow is designed to distribute work across multiple workers that do not neccessarily share a file system. So before you can use the function, you need to get the input files into suitable globally-accessible variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = filehandling.FileHandler()\n",
    "startcrds = fh.load('dhfr.crd')\n",
    "prmtop = fh.load('dhfr.prmtop')\n",
    "em_protocol_1 = fh.load('step1.mdin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Althoughg it's possible to run crossflow kernels interactively, most normally they are run via a crossflow `Client`, so we create one of these, running locally on this machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = clients.Client(local=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can submit the function, with its input arguments, to the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restart, logfile = client.submit(md, em_protocol_1, startcrds, prmtop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The submit call returns immediately, becaue the job has indeed been submitted to the client; however it may not have finished yet. The output arguments, `restart` and `logfile` are `Futures`. You get at the real data, maybe with some wait, by calling the `Future`'s `.result()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile.result().save('test.mdout')\n",
    "restart.result().save('test.rst7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check they are there:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat test.mdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: A workflow\n",
    "\n",
    "Let's make a workflow that:\n",
    "1. Runs a restrained energy mininisation.\n",
    "2. Runs an unrestrained energy minimisation on the final coordinates from step 1.\n",
    "3. Runs a short MD simulation on the final coordinates from step 2.\n",
    "\n",
    "The md input files for steps 2 and 3 are already prepared, and just need to be loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables from the required input files:\n",
    "em_protocol_2 = fh.load('step2.mdin')\n",
    "md_protocol = fh.load('step3.mdin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the jobs. For clarity, we begin at the beginning again:\n",
    "restart1, logfile1 = client.submit(md, em_protocol_1, startcrds, prmtop)\n",
    "print('first stage submitted...')\n",
    "restart2, logfile2 = client.submit(md, em_protocol_2, restart1, prmtop)\n",
    "print('second stage submitted...')\n",
    "restart3, logfile3 = client.submit(md, md_protocol, restart2, prmtop)\n",
    "print('third stage submitted.')\n",
    "# Now we wait for logfile3 to appear:\n",
    "logfile3.result().save('stage3.mdout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat stage3.mdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming all went OK, a couple things to note:\n",
    "1. You were able to re-use the same kernel for all three simulation stages.\n",
    "2. Because you did this, you haven't captured the trajectory file that the third stage will have produced.\n",
    "3. All three kernels use the same prmtop file as an argument - in effect it's a constant.\n",
    "    \n",
    "Let's fix issue 2 first.\n",
    "\n",
    "Make a new kernel that also returns a trajectory file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md_with_traj = kernels.SubprocessKernel('sander.MPI -O -i x.mdin -c x.rst7 -p x.prmtop -o x.mdout -r out.rst7 -x x.nc')\n",
    "md_with_traj.set_inputs(['x.mdin', 'x.rst7', 'x.prmtop'])\n",
    "md_with_traj.set_outputs(['x.nc', 'out.rst7', 'x.mdout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make the prmtop file a constant in both kernels. This means it does not have to appear in the kernel argument list any more (but has the disadvantage that these kernels are now 'hard wired' to only work for DHFR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md2 = md.copy() # Take a copy of the previous version of the kernel\n",
    "md2.set_constant('x.prmtop', prmtop)\n",
    "md_with_traj.set_constant('x.prmtop', prmtop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: A better workflow\n",
    "\n",
    "Here's the workflow re-written to use these improved kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A workflow that runs a two-stage energy minimisation and then an MD simulation\n",
    "restart1, logfile1 = client.submit(md2, em_protocol_1, startcrds)\n",
    "print('first stage submitted...')\n",
    "restart2, logfile2 = client.submit(md2, em_protocol_2, restart1)\n",
    "print('second stage submitted...')\n",
    "trajectory, restart3, logfile3 = client.submit(md_with_traj, md_protocol, restart2)\n",
    "print('final stage submitted, waiting for trajectory file to appear:')\n",
    "t = trajectory.result()\n",
    "print('All done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: interfacing with more Python\n",
    "\n",
    "At this stage you may be thinking \"OK - but nothing here I couldn't do with a bash script\". The power of the workflow comes when you interface your new pythonized-MD functions with other Python tools.\n",
    "\n",
    "Let's make use of the *MDTraj* package for analysis of MD trajectory data. You will use it to calculate the RMSD of the trajectory frames from the starting structure.\n",
    "\n",
    "The MDTraj load() method expects *filenames* as arguments; crossflow `FileHandles` subclass `os.PathLike` so can often be used in Python anywhere a *path* is expected, e.g.:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(logfile3.result()) as f:\n",
    "    for line in f.readlines():\n",
    "        print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However if your Python module is less tolerant (as mdtraj is), you just need to pass the `str()` representation of the object to the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as mdt\n",
    "traj = mdt.load(str(t), top=str(prmtop))\n",
    "print(traj)\n",
    "# Print the rmsd of each frame from the first:\n",
    "print(mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make your workflow identify which snapshot from your trajectory has the highest RMSD from the starting structure, and then energy minimise that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rmsdlist = mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein'))\n",
    "i = np.argmax(rmsdlist)\n",
    "chosen_snapshot = traj[i]\n",
    "print('Energy minimising snapshot {}'.format(i))\n",
    "max_rmsd_minimised, logfile = md.run(em_protocol_2, chosen_snapshot)\n",
    "max_rmsd_minimised.save('max_rmsd.rst7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6: Putting everything together\n",
    "\n",
    "Here's the complete workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_workflow(crd_filename, top_filename, em_step1_filename, em_step2_filename, md_step_filename):\n",
    "    # Over to you!\n",
    "    # Load data:\n",
    "    fh = filehandling.FileHandler()\n",
    "    startcrds =fh.load(crd_filename)\n",
    "    topfile = fh.load(top_filename)\n",
    "    protocol_step_1 = fh.load(em_step1_filename)\n",
    "    protocol_step_2 = fh.load(em_step2_filename)\n",
    "    protocol_step_3 = fh.load(md_step_filename)\n",
    "    \n",
    "    # Create kernels:\n",
    "    \n",
    "    md = kernels.SubprocessKernel('sander.MPI -O -i x.mdin -c x.rst7 -ref x.rst7 -p x.prmtop -o x.mdout -r out.rst7')\n",
    "    md.set_inputs(['x.mdin', 'x.rst7'])\n",
    "    md.set_outputs(['out.rst7'])\n",
    "    md.set_constant('x.prmtop', topfile)\n",
    "    \n",
    "    md_with_traj = kernels.SubprocessKernel('sander.MPI -O -i x.mdin -c x.rst7 -p x.prmtop -o x.mdout -r out.rst7 -x x.nc')\n",
    "    md_with_traj.set_inputs(['x.mdin', 'x.rst7'])\n",
    "    md_with_traj.set_outputs(['x.nc'])\n",
    "    md_with_traj.set_constant('x.prmtop', topfile)\n",
    "    \n",
    "    # Run workflow:\n",
    "    restart1 = client.submit(md, protocol_step_1, startcrds)\n",
    "    restart2 = client.submit(md, protocol_step_2, restart1)\n",
    "    print('running MD steps')\n",
    "    trajectory = client.submit(md_with_traj, protocol_step_3, restart2).result()\n",
    "    traj = mdt.load(str(trajectory), top=str(prmtop))\n",
    "    rmsdlist = mdt.rmsd(traj, traj[0], atom_indices=traj.topology.select('protein'))\n",
    "    i = np.argmax(rmsdlist)\n",
    "    print('Energy minimising snapshot {}'.format(i))\n",
    "    final_crds = md.run(protocol_step_2, traj[i])\n",
    "    \n",
    "    # Return final structure:\n",
    "    return final_crds\n",
    "\n",
    "# Test the workflow:\n",
    "final_crds = my_workflow('dhfr.crd', 'dhfr.prmtop', 'step1.mdin', 'step2.mdin', 'step3.mdin')\n",
    "final_crds.save('final_coordinates.rst7')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
